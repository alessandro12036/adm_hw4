{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "e7d09c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb004fec",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "b60f31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def plot_spectrogram_and_picks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Sampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_audio_picks(audio, duration, hop_size):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        duration (int): [description]\n",
    "        hop_size (int): \n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb3d393",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "12aea576",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "DURATION = 30\n",
    "THRESHOLD = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "aeb6c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(os.path.expanduser(\"~/Downloads/mp3s-32k\"))\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1847c8",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "1c6a92fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762450491db841f5963c83fa68ac4d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tracks_names = []\n",
    "for track in tqdm(mp3_tracks, total=N_TRACKS):\n",
    "    wav_name = convert_mp3_to_wav(str(track))\n",
    "#print(tracks_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b52d744",
   "metadata": {},
   "source": [
    "### Audio signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac408049",
   "metadata": {},
   "source": [
    "### Minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0d9ad6a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    \n",
    "    def __init__(self, n_rows, n_columns):\n",
    "        self.matrix = np.zeros((n_rows, n_columns))\n",
    "        self.i = 0\n",
    "        self.query_signature_matrix = None\n",
    "        self.signature_matrix = None\n",
    "    \n",
    "    \n",
    "    def populate_matrix(self, tracks, tracks_names):\n",
    "        \"\"\"\n",
    "        Populates the characteristic matrix by extracting the peaks and then calling the self.add method. \n",
    "        A string describing in a tidy fashion the data for each track is also created by using regular \n",
    "        expressions and then stored in self.tracks_names.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.tracks_names = []\n",
    "        for idx, audio in enumerate(tqdm(tracks, total=N_TRACKS)):\n",
    "            track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "            #plot_spectrogram_and_picks(track, sr, peaks, onset_env)\n",
    "            self.add(peaks)\n",
    "            track_string = str(audio)\n",
    "            pattern = \"mp3s-32k\\/([^\\/]+)\\/([^\\/]+)\\/[0-9]{2}-([^\\/]+).wav\"\n",
    "            match = re.search(pattern, track_string)\n",
    "            author, album, title = match.group(1), match.group(2), match.group(3)\n",
    "            author = author.replace(\"_\", \" \").capitalize()\n",
    "            album = album.replace(\"_\", \" \").capitalize()\n",
    "            title = title.replace(\"_\", \" \").capitalize()\n",
    "            final_string = f\"Author: {author}\\nAlbum: {album}\\nTitle: {title}\"\n",
    "            self.tracks_names.append(final_string)\n",
    "            assert np.sum(self.matrix[:, idx]) == len(peaks)\n",
    "    \n",
    "    \n",
    "    def add(self, entry):\n",
    "        \"\"\"\n",
    "        Adds each entry to the characteristic matrix, self.matrix[i, j] = 1 if track j presents a peak at position i.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.matrix[entry, self.i] = 1\n",
    "        self.i += 1\n",
    "    \n",
    "    \n",
    "    def _get_random_hashing_function(self, scale):\n",
    "        \"\"\"\n",
    "        Obtains a random hashing function of the modular variety.\n",
    "        \"\"\"\n",
    "        \n",
    "        a = np.random.randint(1, 3*scale)\n",
    "        b = np.random.randint(1, 3*scale)\n",
    "        def hash_func(x):\n",
    "            hashed = (a * x + b) % scale\n",
    "            return hashed\n",
    "        \n",
    "        return hash_func\n",
    "    \n",
    "    \n",
    "    def get_n_hashing_functions(self, n=100):\n",
    "        \"\"\"\n",
    "        Calls _get_random_hashing_function n times and stores the resulting hash functions in self.hash_functions.\n",
    "        \"\"\"\n",
    "        self.hash_functions = []\n",
    "        \n",
    "        for i in range(n):\n",
    "            self.hash_functions.append(self._get_random_hashing_function(self.matrix.shape[0]))\n",
    "    \n",
    "    \n",
    "    def perform_minhash(self, n=100):\n",
    "        \"\"\"\n",
    "        Obtains the signature matrix for each track using minhash. As for current practice, rather than actually\n",
    "        permuting the matrix n times, we simulated this procedure by creating n hashing functions and calling them\n",
    "        for each row number of the characteristic matrix whenever a 1 is present.\n",
    "        \"\"\"\n",
    "        # initalize matrix to infinite since we have to find the minimum values across the permutations simulated\n",
    "        # by the hashing functions\n",
    "        self.get_n_hashing_functions(n)\n",
    "        self.signature_matrix = np.ones((len(self.hash_functions), self.matrix.shape[1])) * np.inf\n",
    "        \n",
    "        for row_i in range(self.matrix.shape[0]):\n",
    "            for hash_i, hash_func in enumerate(self.hash_functions):\n",
    "                 for j in range(self.matrix.shape[1]):\n",
    "                        element = self.matrix[row_i, j]\n",
    "                        if element == 1:\n",
    "                            self.signature_matrix[hash_i, j] = min(self.signature_matrix[hash_i, j], \n",
    "                                                                   hash_func(row_i))\n",
    "                            \n",
    "    \n",
    "    def lsh(self, rows_per_band=THRESHOLD, query=False):\n",
    "        \"\"\"\n",
    "        Performs local sensitivity hashing on the signature matrix. Specifically, the seignature matrix is divided \n",
    "        row-wise into n bands and a final hashing function is performed on each band column-wise. The resulting \n",
    "        indices are then used to store each track information in a specific bucket. Collisions between different\n",
    "        tracks are more likely if the bands are smaller, i.e. the rows_per_band variable (itself defined by the \n",
    "        variable THRESHOLD) is smaller.\n",
    "        \"\"\"\n",
    "        self.rows_per_band = rows_per_band\n",
    "        signature_matrix = self.signature_matrix\n",
    "        self.bucket_hash_function = self._get_random_hashing_function(scale=self.matrix.shape[1])\n",
    "        self.buckets = {}\n",
    "        n_bands = int(np.ceil(signature_matrix.shape[0] / self.rows_per_band))\n",
    "        for band_i in range(n_bands):\n",
    "            start = self.rows_per_band*band_i\n",
    "            end = start + self.rows_per_band\n",
    "            band = signature_matrix[start:end]\n",
    "            for col_i in range(band.shape[1]):\n",
    "                index = tuple(self.bucket_hash_function(band[:, col_i]))\n",
    "                if index in self.buckets.keys():\n",
    "                    self.buckets[index].append(self.tracks_names[col_i])\n",
    "                else:\n",
    "                    self.buckets[index] = [self.tracks_names[col_i]]\n",
    "        \n",
    "        \n",
    "    def process_query(self, query_path):\n",
    "        \"\"\"\n",
    "        The query undergoes the same exact treatment as all the other tracks, that is same parameters and hash functions.\n",
    "        Once we obtain the hashed indices for each band of the query_signature_matrix, we collect the tracks \n",
    "        information found at those locations, check which one is more represented and provide that as the final match.\n",
    "        As an example, if we had previously selected a THRESHOLD value such that we obtain 5 bands for each track, by \n",
    "        processing the query we would obtain 5 different buckets that could theoretically store different songs: the result\n",
    "        that will be chose will be the one present in the most buckets (that is, the result that matched for most bands).\n",
    "        \"\"\"\n",
    "        track, sr, onset_env, peaks = load_audio_picks(query_path, DURATION, HOP_SIZE)\n",
    "\n",
    "        query_matrix = np.zeros((self.matrix.shape[0]))\n",
    "        query_matrix[peaks] = 1\n",
    "        assert np.sum(query_matrix) == len(peaks)\n",
    "        query_signature_matrix = np.ones((len(self.hash_functions))) * np.inf\n",
    "        for i in range(query_matrix.shape[0]):\n",
    "            for hash_i, hash_func in enumerate(self.hash_functions):\n",
    "                element = query_matrix[i]\n",
    "                if element == 1:\n",
    "                    query_signature_matrix[hash_i] = min(hash_func(i), \n",
    "                                                         query_signature_matrix[hash_i])\n",
    "\n",
    "        n_bands = int(np.ceil(self.signature_matrix.shape[0] / self.rows_per_band))\n",
    "        results = []\n",
    "        \n",
    "        for band_i in range(n_bands):\n",
    "            start = self.rows_per_band*band_i\n",
    "            end = start + self.rows_per_band\n",
    "            band = query_signature_matrix[start:end]\n",
    "            index = tuple(self.bucket_hash_function(band))\n",
    "            if index in self.buckets.keys():\n",
    "                results.append(self.buckets[index])\n",
    "        \n",
    "        counter = collections.Counter([result for nested_result in results for result in nested_result])\n",
    "        return counter.most_common()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "f61252e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d330d6f7e1f944a096c1e2d0238fac02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lsh = LSH(1292, N_TRACKS)\n",
    "lsh.populate_matrix(tracks, tracks_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "124e2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh.perform_minhash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "6263a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh.lsh(rows_per_band=THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "34e8e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_queries(folder):\n",
    "    for query in os.listdir(folder):\n",
    "        path = folder + \"/\" + query\n",
    "        result = lsh.process_query(path)\n",
    "        print(f\"{query.capitalize()}:\")\n",
    "        print(result)\n",
    "        print(\"*\"*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "41fea1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track8.wav:\n",
      "Author: Green day\n",
      "Album: American idiot\n",
      "Title: American idiot\n",
      "********\n",
      "Track9.wav:\n",
      "Author: Depeche mode\n",
      "Album: Some great reward\n",
      "Title: Somebody\n",
      "********\n",
      "Track10.wav:\n",
      "Author: Steely dan\n",
      "Album: Katy lied\n",
      "Title: Black friday\n",
      "********\n",
      "Track2.wav:\n",
      "Author: Queen\n",
      "Album: The works\n",
      "Title: I want to break free\n",
      "********\n",
      "Track3.wav:\n",
      "Author: U2\n",
      "Album: October\n",
      "Title: October\n",
      "********\n",
      "Track1.wav:\n",
      "Author: Aerosmith\n",
      "Album: Aerosmith\n",
      "Title: Dream on\n",
      "********\n",
      "Track4.wav:\n",
      "Author: Beatles\n",
      "Album: The white album disc 1\n",
      "Title: Ob-la-di ob-la-da\n",
      "********\n",
      "Track5.wav:\n",
      "Author: Radiohead\n",
      "Album: Ok computer\n",
      "Title: Karma police\n",
      "********\n",
      "Track7.wav:\n",
      "Author: Fleetwood mac\n",
      "Album: Rumours\n",
      "Title: Go your own way\n",
      "********\n",
      "Track6.wav:\n",
      "Author: Led zeppelin\n",
      "Album: Led zeppelin ii\n",
      "Title: Heartbreaker\n",
      "********\n"
     ]
    }
   ],
   "source": [
    "folder = \"/Users/alessandro/Downloads/queries\"\n",
    "test_queries(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e55b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fds]",
   "language": "python",
   "name": "conda-env-fds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
